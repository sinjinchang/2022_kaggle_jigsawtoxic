{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport os\nimport gc\nimport cv2\nimport copy\nimport time\nimport random\nfrom bs4 import BeautifulSoup\nfrom collections import defaultdict\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# For Transformer Models\nfrom transformers import AutoTokenizer, AutoModel,AutoConfig\n\n# Utils\nfrom tqdm import tqdm\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-06T14:34:48.900117Z","iopub.execute_input":"2022-02-06T14:34:48.900424Z","iopub.status.idle":"2022-02-06T14:34:48.908629Z","shell.execute_reply.started":"2022-02-06T14:34:48.90038Z","shell.execute_reply":"2022-02-06T14:34:48.907143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    \n    model_name = '../input/roberta-base'\n        \n    learning_rate = 1e-4\n    epochs = 1\n    train_bs =32\n    valid_bs = 64\n    test_bs = 128\n        \n    seed = 2021\n    max_length = 128\n    min_lr = 1e-7\n    scheduler = 'CosineAnnealingLR' # 学习率衰减策略\n    T_max  = 500\n    weight_decay = 1e-6 # 权重衰减 L2正则化 减少过拟合\n    max_grad_norm = 1.0 # 用于控制梯度膨胀，如果梯度向量的L2模超过max_grad_norm，则等比例缩小\n    num_classes = 1\n    margin = 0.5\n    n_fold = 5\n    n_accululate = 1\n    device= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    \n    hidden_size =768\n    num_hidden_layers = 24\n    \n    dropout = 0.2\n\ntokenizer = AutoTokenizer.from_pretrained(Config.model_name)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:34:48.9115Z","iopub.execute_input":"2022-02-06T14:34:48.912176Z","iopub.status.idle":"2022-02-06T14:34:49.020559Z","shell.execute_reply.started":"2022-02-06T14:34:48.912131Z","shell.execute_reply":"2022-02-06T14:34:49.019626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_PATHS = [\n    '../input/robertabase5fold2-linear-256/Loss-Fold-0.bin',\n    '../input/robertabase5fold2-linear-256/Loss-Fold-1.bin',\n    '../input/robertabase5fold2-linear-256/Loss-Fold-2.bin',\n    '../input/robertabase5fold2-linear-256/Loss-Fold-3.bin',\n    '../input/robertabase5fold2-linear-256/Loss-Fold-4.bin'\n]","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:34:49.02237Z","iopub.execute_input":"2022-02-06T14:34:49.022726Z","iopub.status.idle":"2022-02-06T14:34:49.028627Z","shell.execute_reply.started":"2022-02-06T14:34:49.022659Z","shell.execute_reply":"2022-02-06T14:34:49.027303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed = 42):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(Config.seed)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:34:49.030614Z","iopub.execute_input":"2022-02-06T14:34:49.030962Z","iopub.status.idle":"2022-02-06T14:34:49.042285Z","shell.execute_reply.started":"2022-02-06T14:34:49.030918Z","shell.execute_reply":"2022-02-06T14:34:49.041097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\nval = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:34:49.045328Z","iopub.execute_input":"2022-02-06T14:34:49.045978Z","iopub.status.idle":"2022-02-06T14:34:49.103714Z","shell.execute_reply.started":"2022-02-06T14:34:49.045932Z","shell.execute_reply":"2022-02-06T14:34:49.102738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class JigsawDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        self.df = df\n        self.val = val\n        self.max_len = max_length\n        self.tokenizer = tokenizer\n        self.text = df['text'].values\n        self.p1 = val['less_toxic'].values\n        self.p2 = val['more_toxic'].values\n        \n    def __len__(self):\n        return len(self.val)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        p1 = self.p1[index]\n        p2 = self.p2[index]\n        inputs = self.tokenizer.encode_plus(\n                        text,\n                        truncation=True,\n                        add_special_tokens=True,\n                        max_length=self.max_len,\n                        padding='max_length'\n                    )\n        \n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']        \n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:34:49.105542Z","iopub.execute_input":"2022-02-06T14:34:49.106242Z","iopub.status.idle":"2022-02-06T14:34:49.11615Z","shell.execute_reply.started":"2022-02-06T14:34:49.106194Z","shell.execute_reply":"2022-02-06T14:34:49.115137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = JigsawDataset(df, tokenizer, max_length=Config.max_length)\ntest_loader = DataLoader(test_dataset, batch_size=Config.test_bs,\n                         num_workers=2, shuffle=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:34:49.118028Z","iopub.execute_input":"2022-02-06T14:34:49.118642Z","iopub.status.idle":"2022-02-06T14:34:49.131442Z","shell.execute_reply.started":"2022-02-06T14:34:49.118583Z","shell.execute_reply":"2022-02-06T14:34:49.130239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class JModel(nn.Module):\n    def __init__(self, checkpoint=Config.model_name, Config=Config):\n        super(JModel, self).__init__()\n        self.checkpoint = checkpoint\n        self.bert = AutoModel.from_pretrained(checkpoint, return_dict=False)\n        self.layer_norm = nn.LayerNorm(Config.hidden_size)\n        self.dropout = nn.Dropout(Config.dropout)\n        self.dense = nn.Sequential(\n            nn.Linear(Config.hidden_size, 256),\n            nn.LeakyReLU(negative_slope=0.01),\n            nn.Dropout(Config.dropout),\n            nn.Linear(256, 1)\n        )\n\n    def forward(self, input_ids, attention_mask):\n        _, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = self.layer_norm(pooled_output)\n        pooled_output = self.dropout(pooled_output)\n        preds = self.dense(pooled_output)\n        return preds","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:34:49.14717Z","iopub.execute_input":"2022-02-06T14:34:49.147414Z","iopub.status.idle":"2022-02-06T14:34:49.156949Z","shell.execute_reply.started":"2022-02-06T14:34:49.147385Z","shell.execute_reply":"2022-02-06T14:34:49.155739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef valid_fn(model, dataloader, device):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    PREDS = []\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        outputs = model(ids, mask)\n        PREDS.append(outputs.view(-1).cpu().detach().numpy()) \n    \n    PREDS = np.concatenate(PREDS)\n    gc.collect()\n    \n    return PREDS","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:34:49.159593Z","iopub.execute_input":"2022-02-06T14:34:49.160474Z","iopub.status.idle":"2022-02-06T14:34:49.170092Z","shell.execute_reply.started":"2022-02-06T14:34:49.160425Z","shell.execute_reply":"2022-02-06T14:34:49.168982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_cleaning(text):\n\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:34:49.171863Z","iopub.execute_input":"2022-02-06T14:34:49.172614Z","iopub.status.idle":"2022-02-06T14:34:49.185553Z","shell.execute_reply.started":"2022-02-06T14:34:49.172569Z","shell.execute_reply":"2022-02-06T14:34:49.184521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference(model_paths, dataloader, device):\n    final_preds = []\n    for i, path in enumerate(model_paths):\n        model = JModel(Config.model_name)\n        model.to(Config.device)\n        model.load_state_dict(torch.load(path))\n        \n        print(f\"Getting predictions for model {i+1}\")\n        preds = valid_fn(model, dataloader, device)\n        final_preds.append(preds)\n    \n    final_preds = np.array(final_preds)\n    final_preds = np.mean(final_preds, axis=0)\n    \n    return final_preds","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:34:49.187343Z","iopub.execute_input":"2022-02-06T14:34:49.187797Z","iopub.status.idle":"2022-02-06T14:34:49.200994Z","shell.execute_reply.started":"2022-02-06T14:34:49.187749Z","shell.execute_reply":"2022-02-06T14:34:49.200026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = inference(MODEL_PATHS, test_loader, Config.device)\n\ndf_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ntqdm.pandas()\n    \ndf_val['less_toxic'] = df_val['less_toxic'].progress_apply(text_cleaning)\ndf_val['more_toxic'] = df_val['more_toxic'].progress_apply(text_cleaning)\np1 = model.predict(df_val['less_toxic'])\np2 = model.predict(df_val['more_toxic'])\n# Validation Accuracy\nprint(f'val : {(p1 < p2).mean()}')","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:34:49.203413Z","iopub.execute_input":"2022-02-06T14:34:49.204504Z","iopub.status.idle":"2022-02-06T14:37:52.104384Z","shell.execute_reply.started":"2022-02-06T14:34:49.20446Z","shell.execute_reply":"2022-02-06T14:37:52.102719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['score'] = preds\ndf['score'] = df['score'].rank(method='first')\ndf.drop('text', axis=1, inplace=True)\ndf.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:37:52.106022Z","iopub.status.idle":"2022-02-06T14:37:52.10678Z","shell.execute_reply.started":"2022-02-06T14:37:52.106466Z","shell.execute_reply":"2022-02-06T14:37:52.106498Z"},"trusted":true},"execution_count":null,"outputs":[]}]}